# Spotify_ETL : AWS Serverless Data Pipeline Project

This project demonstrates a complete end-to-end ETL pipeline for processing music metadata using AWS services. It integrates multiple datasets â€” artists, albums, and tracks â€” and transforms them into an analytics-ready format for querying and visualization.

---

## ðŸ—ºï¸ Project Architecture

S3 (raw data)
â”œâ”€â”€ artist.csv
â”œâ”€â”€ albums.csv
â””â”€â”€ tracks.csv
â†“
AWS Glue Visual ETL (joins, cleanup)
â†“
S3 (cleaned output in Parquet)
â†“
AWS Glue Crawler (create catalog)
â†“
Athena (SQL queries)
â†“
QuickSight (visual dashboards)

---

## ðŸ§° Tools & Services Used

- **Amazon S3**: Raw and processed data storage  
- **AWS Glue Studio**: Visual ETL job with joins and transformations  
- **AWS Glue Crawler**: Crawled transformed data into the Glue Data Catalog  
- **AWS Athena**: Ran SQL queries on transformed data  
- **Amazon QuickSight**: Built visual dashboards and charts

---

## ðŸ§ª ETL Pipeline Description

The ETL pipeline is built using AWS Glue Studio (Visual ETL) and performs the following steps:

- Joins artist and album datasets using `artist_id`
- Joins the result with track dataset using `album_id`
- Drops unnecessary or redundant fields
- Outputs the cleaned data to S3 in Parquet format

ðŸ“„ Full description: (https://github.com/bharadwajbairi3/Spotify_ETL/blob/main/Glue/glue%3Aetl_pipeline_description.md)

ðŸ–¼ï¸ Pipeline Diagram:  
![Spotify_ETL Visual Flow](./images/glue_pipeline_screenshot.png)

---

## ðŸ” Athena SQL Queries

Here are some of the queries used for data analysis:

- Top 10 most popular tracks
- Average duration by genre
- Most prolific artists
- Number of songs released per year
- Longest and shortest tracks

ðŸ“„ Full queries: [sql/athena_queries.sql](./sql/athena_queries.sql)

---

## ðŸ“ˆ QuickSight Dashboards

Amazon QuickSight was used to visualize:

- Genre distribution
- Popularity trends
- Year-wise release counts
- Track duration analysis

ðŸ–¼ï¸ Dashboard previews: [quicksight/](./quicksight/dashboard_screenshots/)

---

## ðŸ§  Key Learnings

- Built a fully **serverless** ETL pipeline using AWS Glue Visual ETL  
- Performed **schema inference**, **joins**, and **data type casting**  
- Integrated AWS services for end-to-end analytics â€” from raw data to visualization  
- Practiced building scalable data workflows and dashboards

---

## ðŸ“ Project Structure
aws-etl-pipeline-project/
â”œâ”€â”€ glue/
â”‚ â””â”€â”€ etl_pipeline_description.md
â”œâ”€â”€ sql/
â”‚ â””â”€â”€ athena_queries.sql
â”œâ”€â”€ quicksight/
â”‚ â””â”€â”€ dashboard_screenshots/
â”œâ”€â”€ images/
â”‚ â””â”€â”€ glue_pipeline_screenshot.png
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ sample_input.csv
â”‚ â””â”€â”€ sample_output.csv
â””â”€â”€ README.md

---

## ðŸ§‘â€ðŸ’» Author

**Bharadwaj Bairi**  
AWS Data Engineer | Glue | S3 | Athena | QuickSight  
ðŸ“§ bharadwajbairi3@gmail.com  
ðŸ”— [LinkedIn](https://www.linkedin.com/in/bharadwajbairi)

---

## ðŸ“Œ How to Run This Project

> Note: You need an AWS account with Glue, Athena, S3, and QuickSight access.

1. Upload sample CSV files to an S3 bucket.
2. Open AWS Glue Studio and import or rebuild the visual ETL job.
3. Create a crawler to catalog the output data.
4. Run Athena queries using the cataloged table.
5. Connect QuickSight to Athena and build visualizations.
